{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgGvNJs0vayE"
      },
      "source": [
        "# CAN BUS decoding script (To be used in pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZDpZGdGxfrO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "from typing import List, Dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4e86FUmTrPQ",
        "outputId": "1cc22fe0-d63e-4316-dd8e-94150cbce7a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3136187441.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  chunk[\"Timestamp\"] = pd.to_datetime(chunk[\"Time scale\"], errors=\"coerce\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Complete! Data is decoded, chronologically sorted, and saved.\n",
            " File: decoded_telemetry.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "INPUT_FILE = \"can_log_dataset.csv\"\n",
        "OUTPUT_FILE = \"decoded_telemetry.csv\"\n",
        "CHUNK_SIZE = 50000  # Memory saver\n",
        "\n",
        "def hex_to_bytes(hex_str):\n",
        "    if pd.isna(hex_str): return []\n",
        "    try:\n",
        "        return [int(x, 16) for x in str(hex_str).strip().split()]\n",
        "    except ValueError: return []\n",
        "\n",
        "def get_le_val(data, start, length=2, signed=False):\n",
        "    if len(data) < start + length: return 0\n",
        "    val = 0\n",
        "    for i in range(length):\n",
        "        val |= (data[start + i] << (8 * i))\n",
        "    if signed:\n",
        "        max_val = 1 << (length * 8)\n",
        "        if val >= max_val // 2: val -= max_val\n",
        "    return val\n",
        "\n",
        "first_chunk = True\n",
        "last_values = None   # Context for forward fill\n",
        "\n",
        "try:\n",
        "    reader = pd.read_csv(\n",
        "        INPUT_FILE,\n",
        "        encoding=\"latin1\",\n",
        "        sep=None,\n",
        "        engine=\"python\",\n",
        "        skipinitialspace=True,\n",
        "        chunksize=CHUNK_SIZE\n",
        "    )\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {INPUT_FILE} not found.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "for chunk in reader:\n",
        "    # Clean Headers & Data\n",
        "    chunk.columns = chunk.columns.str.strip()\n",
        "    for col in chunk.select_dtypes(include=\"object\"):\n",
        "        chunk[col] = chunk[col].str.strip()\n",
        "\n",
        "    # Time Sort (Ensures Chronological Order)\n",
        "    chunk[\"Timestamp\"] = pd.to_datetime(chunk[\"Time scale\"], errors=\"coerce\")\n",
        "    chunk = chunk.dropna(subset=[\"Timestamp\"]).sort_values(\"Timestamp\")\n",
        "\n",
        "    decoded_rows = []\n",
        "\n",
        "    # Decode Frames\n",
        "    for _, row in chunk.iterrows():\n",
        "        try:\n",
        "            msg_id = int(str(row[\"Frame Id\"]), 16)\n",
        "            data = hex_to_bytes(row[\"Data(Hex)\"])\n",
        "            ts = row[\"Timestamp\"]\n",
        "            entry = {\"Time\": ts}\n",
        "\n",
        "            # Safety & Network\n",
        "            if msg_id == 0x04 and len(data) >= 1:\n",
        "                entry[\"Safety_EStop\"] = data[0]\n",
        "            elif msg_id == 0x05 and len(data) >= 1:\n",
        "                entry[\"Safety_MotorsLocked\"] = data[0]\n",
        "\n",
        "            # Node Status Request\n",
        "            elif msg_id == 0x07 and len(data) >= 1:\n",
        "                entry[\"Node_status_request\"] = data[0] # 0=All, or specific ID\n",
        "\n",
        "            # Node Heartbeats\n",
        "            elif msg_id in [0x08, 0x09, 0x0A, 0x0D, 0x0F, 0x10] and len(data) >= 1:\n",
        "                status_map = {\n",
        "                    0x08: \"Status_ECU\", 0x09: \"Status_BMS\", 0x0A: \"Status_TPS\",\n",
        "                    0x0D: \"Status_FW\",  0x0F: \"Status_RLW\", 0x10: \"Status_RRW\"\n",
        "                }\n",
        "                entry[status_map[msg_id]] = data[0]\n",
        "\n",
        "            # --- 0x20: Throttle & Brake (New Logic) ---\n",
        "            elif msg_id == 0x20 and len(data) >= 5:\n",
        "                # B0: Throttle %\n",
        "                entry[\"Throttle_Pct\"] = data[0] * 0.4\n",
        "\n",
        "                # B2: Brake Pressure (Front/Default)\n",
        "                entry[\"Brake_Pressure_Front_kPa\"] = data[2] * 4.0\n",
        "\n",
        "                # B3: Brake Pressure (Rear) - If 255, B2 is default (Rear is unused/unknown)\n",
        "                if data[3] != 255:\n",
        "                    entry[\"Brake_Pressure_Rear_kPa\"] = data[3] * 4.0\n",
        "                else:\n",
        "                    entry[\"Brake_Pressure_Rear_kPa\"] = 0\n",
        "\n",
        "                # B4: Brake Pedal %\n",
        "                entry[\"Brake_Pedal_Pct\"] = data[4] * 0.4\n",
        "\n",
        "            # --- 0x22: Steering (Existing Logic) ---\n",
        "            elif msg_id == 0x22 and len(data) >= 2:\n",
        "                entry[\"Steering_Angle_Deg\"] = get_le_val(data, 0, signed=True) * 0.1 - 180\n",
        "\n",
        "            # --- 0x24: Battery Stats (New Logic) ---\n",
        "            elif msg_id == 0x24 and len(data) >= 8: # Assuming 8 bytes for full frame\n",
        "                # B0-B1: Voltage\n",
        "                entry[\"Battery_Voltage_V\"] = get_le_val(data, 0, 2) * 0.1\n",
        "\n",
        "                # B2-B3: Current (Offset -320)\n",
        "                # User formula: -320 + (B3*256 + B2)*0.1\n",
        "                raw_curr = get_le_val(data, 2, 2, signed=False)\n",
        "                entry[\"Battery_Current_A\"] = -320 + (raw_curr * 0.1)\n",
        "\n",
        "                # B4: SOC\n",
        "                entry[\"Battery_SOC_Pct\"] = data[4]\n",
        "\n",
        "                # B5-B6: Resistance\n",
        "                # User formula: (B6*256+B5)*1000\n",
        "                raw_res = get_le_val(data, 5, 2, signed=False)\n",
        "                entry[\"Battery_Resistance_Ohms\"] = raw_res * 0.000001\n",
        "\n",
        "                # B7: Highest Cell Temp\n",
        "                # User formula: B8 - 40. Assuming B8 is 8th byte (index 7).\n",
        "                entry[\"Battery_Temp_Max_C\"] = data[7] - 40.0\n",
        "\n",
        "            # --- 0x25: Voltage Rails (New Logic) ---\n",
        "            elif msg_id == 0x25 and len(data) >= 3:\n",
        "                # B1: 5V Rail\n",
        "                entry[\"Voltage_5V_Rail_V\"] = data[1] / 36.0\n",
        "                # B2: 12V Rail\n",
        "                entry[\"Voltage_12V_Rail_V\"] = data[2] / 10.0\n",
        "\n",
        "            # --- 0x30: Target Throttles (Existing) ---\n",
        "            elif msg_id == 0x30 and len(data) >= 4:\n",
        "                entry[\"Target_Thr_FL\"] = data[0] * 0.4\n",
        "                entry[\"Target_Thr_FR\"] = data[1] * 0.4\n",
        "                entry[\"Target_Thr_RL\"] = data[2] * 0.4\n",
        "                entry[\"Target_Thr_RR\"] = data[3] * 0.4\n",
        "\n",
        "            # --- 0x34-0x37: Wheel Speed (Existing) ---\n",
        "            elif msg_id in [0x34, 0x35, 0x36, 0x37] and len(data) >= 2:\n",
        "                wheel_map = {0x34: \"FL\", 0x35: \"FR\", 0x36: \"RL\", 0x37: \"RR\"}\n",
        "                entry[f\"Wheel_RPM_{wheel_map[msg_id]}\"] = get_le_val(data, 0) / 30.0\n",
        "\n",
        "            # --- 0x38: Vehicle Speed (New Logic - Replaces IMU) ---\n",
        "            elif msg_id == 0x38 and len(data) >= 2:\n",
        "                # User formula: (B1*256 + B0)/256\n",
        "                raw_speed = get_le_val(data, 0, 2, signed=False)\n",
        "                entry[\"Vehicle_Speed_kmh\"] = raw_speed / 256.0\n",
        "\n",
        "            if len(entry) > 1:\n",
        "                decoded_rows.append(entry)\n",
        "\n",
        "        except Exception: continue\n",
        "\n",
        "    # 4. Save Logic (with Forward Fill)\n",
        "    if decoded_rows:\n",
        "        out_df = pd.DataFrame(decoded_rows)\n",
        "\n",
        "        out_df = out_df.sort_values(\"Time\").reset_index(drop=True)\n",
        "\n",
        "\n",
        "        # Continui  ty: Merge with previous chunk's last row\n",
        "        if last_values is not None:\n",
        "            out_df = pd.concat([last_values, out_df], ignore_index=True)\n",
        "\n",
        "        # Fill missing values (Forward Fill)\n",
        "        out_df = out_df.ffill()\n",
        "\n",
        "        out_df = out_df.dropna(how=\"any\")\n",
        "\n",
        "\n",
        "        # Save last valid row for next chunk's context\n",
        "        last_values = out_df.tail(1)\n",
        "\n",
        "        # Remove the carry-over row (to avoid duplicates or edge cases) and save\n",
        "        out_df = out_df.iloc[:-1]\n",
        "        out_df[\"Time\"] = out_df[\"Time\"].dt.strftime('%H:%M:%S.%f').str[:-3]\n",
        "\n",
        "        if not out_df.empty:\n",
        "            out_df.to_csv(\n",
        "                OUTPUT_FILE,\n",
        "                mode=\"w\" if first_chunk else \"a\",\n",
        "                header=first_chunk,\n",
        "                index=False\n",
        "            )\n",
        "            first_chunk = False\n",
        "\n",
        "print(\" Complete! Data is decoded, chronologically sorted, and saved.\")\n",
        "print(\" File:\", OUTPUT_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWrVJhQnnL8O"
      },
      "source": [
        "# Model Training (Isolation forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6CB_Ioy2E-k",
        "outputId": "e260866a-0860-4a9f-87eb-7c392a961ca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (1939, 17)\n",
            "Columns: ['Vehicle_Speed_kmh', 'Vehicle_Speed_RPM_mean', 'Wheel_RPM_std', 'Battery_Voltage_V', 'Battery_Current_A', 'Battery_Power_W', 'Power_per_Speed', 'Battery_SOC_Pct', 'Battery_Resistance_Ohms', 'Battery_Temp_Max_C', 'Temp_Stress_Index', 'Throttle_Pct', 'Torque_Command_Error', 'Brake_Pedal_Pct', 'Brake_Pressure_Front_kPa', 'Brake_Pressure_Rear_kPa', 'Brake_Pressure_Diff']\n",
            "Training samples: 1939\n",
            "\n",
            "Threshold: 0.5991845223399249\n",
            "Anomalies detected: 39\n",
            "\n",
            "✅ Model saved: isolation_forest_fixed.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "INPUT_FILE = \"features_only.csv\"\n",
        "MODEL_FILE = \"isolation_forest_fixed.pkl\"\n",
        "\n",
        "\n",
        "df = pd.read_csv(INPUT_FILE)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "X = df.copy()\n",
        "\n",
        "# Drop NaNs\n",
        "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "print(\"Training samples:\", len(X))\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "iso = IsolationForest(\n",
        "    n_estimators=200,\n",
        "    contamination=0.05,   # 5% anomalies\n",
        "    random_state=42\n",
        "    max_samples=Auto\n",
        ")\n",
        "\n",
        "iso.fit(X_scaled)\n",
        "\n",
        "scores = iso.decision_function(X_scaled)   # higher = normal\n",
        "raw_scores = iso.score_samples(X_scaled)   # lower = more anomalous\n",
        "\n",
        "# Convert to anomaly score (positive = more anomalous)\n",
        "anomaly_score = -raw_scores\n",
        "\n",
        "df[\"if_score\"] = anomaly_score\n",
        "\n",
        "\n",
        "threshold = np.percentile(anomaly_score, 95)\n",
        "\n",
        "df[\"if_anomaly\"] = (df[\"if_score\"] > threshold).astype(int)\n",
        "\n",
        "print(\"\\nThreshold:\", threshold)\n",
        "print(\"Anomalies detected:\", df[\"if_anomaly\"].sum())\n",
        "\n",
        "model_bundle = {\n",
        "    \"model\": iso,\n",
        "    \"scaler\": scaler,\n",
        "    \"features\": X.columns.tolist(),\n",
        "    \"threshold\": threshold\n",
        "}\n",
        "\n",
        "joblib.dump(model_bundle, MODEL_FILE)\n",
        "\n",
        "print(\"\\n✅ Model saved:\", MODEL_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OApWj7Zu4lHT",
        "outputId": "d2f43d96-432d-4eeb-bc4f-9ece536bde05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded features: ['Vehicle_Speed_kmh', 'Vehicle_Speed_RPM_mean', 'Wheel_RPM_std', 'Battery_Voltage_V', 'Battery_Current_A', 'Battery_Power_W', 'Power_per_Speed', 'Battery_SOC_Pct', 'Battery_Resistance_Ohms', 'Battery_Temp_Max_C', 'Temp_Stress_Index', 'Throttle_Pct', 'Torque_Command_Error', 'Brake_Pedal_Pct', 'Brake_Pressure_Front_kPa', 'Brake_Pressure_Rear_kPa', 'Brake_Pressure_Diff']\n",
            "Threshold: 0.5991845223399249\n",
            "\n",
            "===== TEST SAMPLE =====\n",
            "Vehicle_Speed_kmh: 1.0\n",
            "Vehicle_Speed_RPM_mean: 1.0\n",
            "Wheel_RPM_std: 1.0\n",
            "Battery_Voltage_V: 1.0\n",
            "Battery_Current_A: 1000.0\n",
            "Battery_Power_W: 1.0\n",
            "Power_per_Speed: 1.0\n",
            "Battery_SOC_Pct: 1.0\n",
            "Battery_Resistance_Ohms: 1.0\n",
            "Battery_Temp_Max_C: 1.0\n",
            "Temp_Stress_Index: 1.0\n",
            "Throttle_Pct: 1.0\n",
            "Torque_Command_Error: 1.0\n",
            "Brake_Pedal_Pct: 1.0\n",
            "Brake_Pressure_Front_kPa: 1.0\n",
            "Brake_Pressure_Rear_kPa: 1.0\n",
            "Brake_Pressure_Diff: 1.0\n",
            "\n",
            "===== RESULT =====\n",
            "Anomaly detected!\n",
            "Anomaly score: 0.7744913748748863\n",
            "Threshold: 0.5991845223399249\n",
            "Confidence: 1.292573578631141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "\n",
        "model_bundle = joblib.load(\"isolation_forest_fixed.pkl\")\n",
        "\n",
        "model = model_bundle[\"model\"]\n",
        "scaler = model_bundle[\"scaler\"]\n",
        "FEATURES = model_bundle[\"features\"]\n",
        "threshold = model_bundle[\"threshold\"]\n",
        "\n",
        "print(\"Loaded features:\", FEATURES)\n",
        "print(\"Threshold:\", threshold)\n",
        "\n",
        "\n",
        "sample = np.zeros((1, len(FEATURES)))\n",
        "\n",
        "# Fill with reasonable baseline values\n",
        "for i, f in enumerate(FEATURES):\n",
        "    sample[0][i] = 1.0  # generic baseline\n",
        "\n",
        "\n",
        "test_sample = sample.copy()\n",
        "\n",
        "# Example: spike battery current if exists\n",
        "if \"Battery_Current_A\" in FEATURES:\n",
        "    idx = FEATURES.index(\"Battery_Current_A\")\n",
        "    test_sample[0][idx] = 1000  # extreme anomaly\n",
        "\n",
        "print(\"\\n===== TEST SAMPLE =====\")\n",
        "for f, v in zip(FEATURES, test_sample[0]):\n",
        "    print(f\"{f}: {v}\")\n",
        "\n",
        "\n",
        "X_scaled = scaler.transform(test_sample)\n",
        "\n",
        "raw_score = model.score_samples(X_scaled)[0]\n",
        "anomaly_score = -raw_score\n",
        "\n",
        "\n",
        "print(\"\\n===== RESULT =====\")\n",
        "\n",
        "if anomaly_score > threshold:\n",
        "    print(\"Anomaly detected!\")\n",
        "else:\n",
        "    print(\"Normal\")\n",
        "\n",
        "print(\"Anomaly score:\", anomaly_score)\n",
        "print(\"Threshold:\", threshold)\n",
        "\n",
        "confidence = anomaly_score / (threshold + 1e-6)\n",
        "print(\"Confidence:\", confidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRj2piiTq5dr",
        "outputId": "0bf7eb59-af7d-43e3-aa07-a23f247979f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Header file generated: iforest_model.h\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "bundle = joblib.load(\"isolation_forest_fixed.pkl\")\n",
        "\n",
        "iso = bundle[\"model\"]\n",
        "scaler = bundle[\"scaler\"]\n",
        "features = bundle[\"features\"]\n",
        "threshold = bundle[\"threshold\"]\n",
        "\n",
        "with open(\"iforest_model.h\", \"w\") as f:\n",
        "\n",
        "    f.write(\"#ifndef IFOREST_MODEL_H\\n\")\n",
        "    f.write(\"#define IFOREST_MODEL_H\\n\\n\")\n",
        "\n",
        "    f.write(f\"#define NUM_FEATURES {len(features)}\\n\")\n",
        "    f.write(f\"#define NUM_TREES {len(iso.estimators_)}\\n\\n\")\n",
        "\n",
        "    \n",
        "    f.write(\"// Scaler mean\\n\")\n",
        "    f.write(\"float scaler_mean[NUM_FEATURES] = {\")\n",
        "    f.write(\",\".join(map(str, scaler.mean_)))\n",
        "    f.write(\"};\\n\\n\")\n",
        "\n",
        "    f.write(\"// Scaler scale\\n\")\n",
        "    f.write(\"float scaler_scale[NUM_FEATURES] = {\")\n",
        "    f.write(\",\".join(map(str, scaler.scale_)))\n",
        "    f.write(\"};\\n\\n\")\n",
        "\n",
        "   \n",
        "    f.write(f\"float IF_THRESHOLD = {threshold};\\n\\n\")\n",
        "\n",
        "    \n",
        "    for i, est in enumerate(iso.estimators_):\n",
        "        tree = est.tree_\n",
        "\n",
        "        f.write(f\"// ===== TREE {i} =====\\n\")\n",
        "\n",
        "        f.write(f\"int tree_{i}_feature[] = {{\")\n",
        "        f.write(\",\".join(map(str, tree.feature)))\n",
        "        f.write(\"};\\n\")\n",
        "\n",
        "        f.write(f\"float tree_{i}_threshold[] = {{\")\n",
        "        f.write(\",\".join(map(str, tree.threshold)))\n",
        "        f.write(\"};\\n\")\n",
        "\n",
        "        f.write(f\"int tree_{i}_left[] = {{\")\n",
        "        f.write(\",\".join(map(str, tree.children_left)))\n",
        "        f.write(\"};\\n\")\n",
        "\n",
        "        f.write(f\"int tree_{i}_right[] = {{\")\n",
        "        f.write(\",\".join(map(str, tree.children_right)))\n",
        "        f.write(\"};\\n\\n\")\n",
        "\n",
        "    f.write(\"#endif\\n\")\n",
        "\n",
        "print(\"Header file generated: iforest_model.h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkK5O30_PAY0"
      },
      "source": [
        "# K-means clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbcFTMQ3nGnR",
        "outputId": "de32612b-62a8-4014-ba40-e9005014c974"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3442707056.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df = pd.read_csv(INPUT_FILE, parse_dates=[\"Time\"])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (1939, 28)\n",
            "\n",
            "Best K: 5\n",
            "Scores: {2: np.float64(0.9193560905206294), 3: np.float64(0.9529832783569747), 4: np.float64(0.99870644744024), 5: np.float64(1.0)}\n",
            "\n",
            "Threshold: 1.2889857856405219e-14\n",
            "Anomalies: 0\n",
            "\n",
            "✅ Model saved as: kmeans_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "INPUT_FILE = \"decoded_telemetry.csv\"\n",
        "OUTPUT_FILE = \"telemetry_with_kmeans.csv\"\n",
        "MODEL_FILE = \"kmeans_model.pkl\"\n",
        "\n",
        "\n",
        "df = pd.read_csv(INPUT_FILE, parse_dates=[\"Time\"])\n",
        "df = df.sort_values(\"Time\").reset_index(drop=True)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "#Feature engineering\n",
        "rpm_cols = [c for c in df.columns if \"Wheel_RPM\" in c]\n",
        "\n",
        "df[\"Vehicle_Speed_RPM_mean\"] = df[rpm_cols].mean(axis=1)\n",
        "df[\"Wheel_RPM_std\"] = df[rpm_cols].std(axis=1)\n",
        "\n",
        "df[\"Battery_Power_W\"] = df[\"Battery_Voltage_V\"] * df[\"Battery_Current_A\"]\n",
        "\n",
        "df[\"Power_per_Speed\"] = df[\"Battery_Power_W\"] / (\n",
        "    df[\"Vehicle_Speed_kmh\"] + 1e-3\n",
        ")\n",
        "\n",
        "thr_cols = [\"Target_Thr_FL\",\"Target_Thr_FR\",\"Target_Thr_RL\",\"Target_Thr_RR\"]\n",
        "df[\"Target_Thr_mean\"] = df[thr_cols].mean(axis=1)\n",
        "\n",
        "df[\"Torque_Command_Error\"] = (\n",
        "    df[\"Target_Thr_mean\"] - df[\"Throttle_Pct\"]\n",
        ").abs()\n",
        "\n",
        "df[\"Brake_Pressure_Diff\"] = (\n",
        "    df[\"Brake_Pressure_Front_kPa\"] -\n",
        "    df[\"Brake_Pressure_Rear_kPa\"]\n",
        ").abs()\n",
        "\n",
        "df[\"Temp_Stress_Index\"] = (\n",
        "    df[\"Battery_Temp_Max_C\"] *\n",
        "    df[\"Battery_Current_A\"].abs()\n",
        ")\n",
        "\n",
        "\n",
        "FEATURES = [\n",
        "    \"Vehicle_Speed_kmh\",\n",
        "    \"Vehicle_Speed_RPM_mean\",\n",
        "    \"Wheel_RPM_std\",\n",
        "    \"Battery_Voltage_V\",\n",
        "    \"Battery_Current_A\",\n",
        "    \"Battery_Power_W\",\n",
        "    \"Power_per_Speed\",\n",
        "    \"Battery_SOC_Pct\",\n",
        "    \"Battery_Resistance_Ohms\",\n",
        "    \"Battery_Temp_Max_C\",\n",
        "    \"Temp_Stress_Index\",\n",
        "    \"Throttle_Pct\",\n",
        "    \"Torque_Command_Error\",\n",
        "    \"Brake_Pedal_Pct\",\n",
        "    \"Brake_Pressure_Front_kPa\",\n",
        "    \"Brake_Pressure_Rear_kPa\",\n",
        "    \"Brake_Pressure_Diff\"\n",
        "]\n",
        "\n",
        "FEATURES = [c for c in FEATURES if c in df.columns]\n",
        "\n",
        "X = df[FEATURES].dropna()\n",
        "df = df.loc[X.index]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "K_RANGE = range(2, 6)\n",
        "scores = {}\n",
        "\n",
        "for k in K_RANGE:\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
        "    labels = km.fit_predict(X_scaled)\n",
        "    scores[k] = silhouette_score(X_scaled, labels)\n",
        "\n",
        "best_k = max(scores, key=scores.get)\n",
        "\n",
        "print(\"\\nBest K:\", best_k)\n",
        "print(\"Scores:\", scores)\n",
        "\n",
        "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=30)\n",
        "df[\"cluster\"] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "distances = np.linalg.norm(\n",
        "    X_scaled - centroids[df[\"cluster\"]],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "df[\"kmeans_distance\"] = distances\n",
        "\n",
        "threshold = np.percentile(distances, 95)\n",
        "\n",
        "df[\"kmeans_anomaly\"] = (distances > threshold).astype(int)\n",
        "\n",
        "print(\"\\nThreshold:\", threshold)\n",
        "print(\"Anomalies:\", df[\"kmeans_anomaly\"].sum())\n",
        "\n",
        "df.to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "model_bundle = {\n",
        "    \"kmeans\": kmeans,\n",
        "    \"scaler\": scaler,\n",
        "    \"features\": FEATURES,\n",
        "    \"threshold\": threshold\n",
        "}\n",
        "\n",
        "joblib.dump(model_bundle, MODEL_FILE)\n",
        "\n",
        "print(\"\\nModel saved as:\", MODEL_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO_-4OmCgsnr",
        "outputId": "368eb8a5-fdb1-48cb-9ed8-3bce5cce0333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded features: ['Vehicle_Speed_kmh', 'Vehicle_Speed_RPM_mean', 'Wheel_RPM_std', 'Battery_Voltage_V', 'Battery_Current_A', 'Battery_Power_W', 'Power_per_Speed', 'Battery_SOC_Pct', 'Battery_Resistance_Ohms', 'Battery_Temp_Max_C', 'Temp_Stress_Index', 'Throttle_Pct', 'Torque_Command_Error', 'Brake_Pedal_Pct', 'Brake_Pressure_Front_kPa', 'Brake_Pressure_Rear_kPa', 'Brake_Pressure_Diff']\n",
            "Threshold: 1.2889857856405219e-14\n",
            "\n",
            "===== TEST SAMPLE =====\n",
            "Vehicle_Speed_kmh: 10.0\n",
            "Vehicle_Speed_RPM_mean: 100.0\n",
            "Wheel_RPM_std: 5.0\n",
            "Battery_Voltage_V: 48.0\n",
            "Battery_Current_A: 1000.0\n",
            "Battery_Power_W: 480.0\n",
            "Power_per_Speed: 40.0\n",
            "Battery_SOC_Pct: 80.0\n",
            "Battery_Resistance_Ohms: 0.01\n",
            "Battery_Temp_Max_C: 35.0\n",
            "Temp_Stress_Index: 350.0\n",
            "Throttle_Pct: 20.0\n",
            "Torque_Command_Error: 2.0\n",
            "Brake_Pedal_Pct: 10.0\n",
            "Brake_Pressure_Front_kPa: 200.0\n",
            "Brake_Pressure_Rear_kPa: 180.0\n",
            "Brake_Pressure_Diff: 20.0\n",
            "\n",
            "===== RESULT =====\n",
            "Anomaly detected!\n",
            "Cluster: 4\n",
            "Distance: 1359.7224949887225\n",
            "Threshold: 1.2889857856405219e-14\n",
            "Confidence: 1359722477.4620929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "\n",
        "model_bundle = joblib.load(\"kmeans_model.pkl\")\n",
        "\n",
        "kmeans = model_bundle[\"kmeans\"]\n",
        "scaler = model_bundle[\"scaler\"]\n",
        "FEATURES = model_bundle[\"features\"]\n",
        "threshold = model_bundle[\"threshold\"]\n",
        "\n",
        "print(\"Loaded features:\", FEATURES)\n",
        "print(\"Threshold:\", threshold)\n",
        "\n",
        "sample = np.array([[\n",
        "    10,     # speed\n",
        "    100,    # rpm mean\n",
        "    5,      # rpm std\n",
        "    48,     # voltage\n",
        "    10,     # current\n",
        "    480,    # power\n",
        "    40,     # power/speed\n",
        "    80,     # SOC\n",
        "    0.01,   # resistance\n",
        "    35,     # temp\n",
        "    350,    # temp stress\n",
        "    20,     # throttle\n",
        "    2,      # torque error\n",
        "    10,     # brake pedal\n",
        "    200,    # brake front\n",
        "    180,    # brake rear\n",
        "    20      # brake diff\n",
        "]])\n",
        "\n",
        "\n",
        "test_sample = sample.copy()\n",
        "\n",
        "\n",
        "test_sample[0][FEATURES.index(\"Battery_Current_A\")] = 1000\n",
        "\n",
        "print(\"\\n===== TEST SAMPLE =====\")\n",
        "for f, v in zip(FEATURES, test_sample[0]):\n",
        "    print(f\"{f}: {v}\")\n",
        "\n",
        "\n",
        "X_scaled = scaler.transform(test_sample)\n",
        "\n",
        "\n",
        "cluster = kmeans.predict(X_scaled)[0]\n",
        "\n",
        "centroid = kmeans.cluster_centers_[cluster]\n",
        "\n",
        "distance = np.linalg.norm(X_scaled[0] - centroid)\n",
        "\n",
        "\n",
        "print(\"\\n===== RESULT =====\")\n",
        "\n",
        "if distance > threshold:\n",
        "    print(\"Anomaly detected!\")\n",
        "else:\n",
        "    print(\"Normal\")\n",
        "\n",
        "print(\"Cluster:\", cluster)\n",
        "print(\"Distance:\", distance)\n",
        "print(\"Threshold:\", threshold)\n",
        "\n",
        "# Confidence (normalized)\n",
        "confidence = distance / (threshold + 1e-6)\n",
        "print(\"Confidence:\", confidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3s_6C5z2yuI"
      },
      "outputs": [],
      "source": [
        "df[FEATURES].to_csv(\"features_only.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJzRffe_4q4V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
